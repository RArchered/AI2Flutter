{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62dd6393",
   "metadata": {},
   "source": [
    "## 1.导入依赖以及网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ec386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 18:41:47.860030: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 18:41:48.821623: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-19 18:41:49.246150: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-19 18:41:51.382457: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-19 18:41:51.382547: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-19 18:41:51.382557: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# 加载网络结构\n",
    "%run AI2Flutter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e843ce40",
   "metadata": {},
   "source": [
    "## 2.实例化网络，并设置模型输入形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a88463e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_2 (Encoder)         multiple                  12877824  \n",
      "                                                                 \n",
      " decoder_2 (Decoder)         multiple                  21294080  \n",
      "                                                                 \n",
      " dense_50 (Dense)            multiple                  257000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,428,904\n",
      "Trainable params: 34,428,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "num_layers = 4\n",
    "d_model = 256\n",
    "dff = 2048\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "input_vocab = 1000  # 每个数字在[0,999]之间，997表示起点，998表示生成终点，999表示节点之间的分隔符\n",
    "output_vocab = 1000  # \n",
    "\n",
    "# 权重保存位置\n",
    "save_weight_path = \"./model_weight/model_1\"\n",
    "save_path = \"./model/model_1\"\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab=input_vocab,\n",
    "    output_vocab=output_vocab,\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "# 使用996作为填充，故考虑loss时不考虑996\n",
    "def masked_loss(label, pred):\n",
    "  print(label)  \n",
    "  mask = label == 996\n",
    "  print(mask)\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 996\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "# 优化器采用Adam，学习率自定义\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy]\n",
    ")\n",
    "# 设置模型输入形状\n",
    "transformer((tf.keras.layers.Input(shape=(None,)),\n",
    "             tf.keras.layers.Input(shape=(None,))))\n",
    "# 网络概览\n",
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae69974",
   "metadata": {},
   "source": [
    "## 3.加载已经训练的权重，方便继续训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87e42df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x139ea2c40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载已训练权重\n",
    "transformer.load_weights(save_weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e276f7f",
   "metadata": {},
   "source": [
    "## 4.加载数据集训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d72bf980",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run AI2Flutter_demo_data.py\n",
    "# 数据规模\n",
    "train_seqs_num = 1000\n",
    "validation_seqs_num = 100\n",
    "# 生成随机数据集\n",
    "input_data, output_data, output_label = demo_generate_data(train_seqs_num)\n",
    "vali_input_data, vali_output_data, vali_output_label = demo_generate_data(validation_seqs_num)\n",
    "\n",
    "# 训练集\n",
    "train_input = tf.data.Dataset.from_generator(\n",
    "    lambda: input_data, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)))\n",
    "train_output = tf.data.Dataset.from_generator(\n",
    "    lambda: output_data, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)))\n",
    "train_label = tf.data.Dataset.from_generator(\n",
    "    lambda: output_label, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)))\n",
    "train_dataset = tf.data.Dataset.zip(((train_input, train_output), train_label))\n",
    "# batch设置\n",
    "train_dataset = train_dataset.padded_batch(2, padding_values=996.0)\n",
    "\n",
    "# 验证集\n",
    "vali_input = tf.data.Dataset.from_generator(\n",
    "    lambda: vali_input_data, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)))\n",
    "vali_output = tf.data.Dataset.from_generator(\n",
    "    lambda: vali_output_data, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)))\n",
    "vali_label = tf.data.Dataset.from_generator(\n",
    "    lambda: vali_output_label, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)))\n",
    "vali_dataset = tf.data.Dataset.zip(((vali_input, vali_output), vali_label))\n",
    "vali_dataset = vali_dataset.padded_batch(1, padding_values=996.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e83116a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "Tensor(\"IteratorGetNext:2\", shape=(None, None), dtype=float32)\n",
      "Tensor(\"masked_loss/NotEqual:0\", shape=(None, None), dtype=bool)\n",
      "Tensor(\"IteratorGetNext:2\", shape=(None, None), dtype=float32)\n",
      "Tensor(\"masked_loss/NotEqual:0\", shape=(None, None), dtype=bool)\n",
      "    499/Unknown - 20s 25ms/step - loss: 3.6569 - masked_accuracy: 0.4402Tensor(\"IteratorGetNext:2\", shape=(None, None), dtype=float32)\n",
      "Tensor(\"masked_loss/NotEqual:0\", shape=(None, None), dtype=bool)\n",
      "500/500 [==============================] - 22s 31ms/step - loss: 3.6555 - masked_accuracy: 0.4403 - val_loss: 2.7198 - val_masked_accuracy: 0.5146\n",
      "Epoch 2/4\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 2.5625 - masked_accuracy: 0.5361 - val_loss: 1.8940 - val_masked_accuracy: 0.6720\n",
      "Epoch 3/4\n",
      "500/500 [==============================] - 14s 27ms/step - loss: 1.2267 - masked_accuracy: 0.8025 - val_loss: 0.7396 - val_masked_accuracy: 0.9006\n",
      "Epoch 4/4\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.8273 - masked_accuracy: 0.8689 - val_loss: 0.9262 - val_masked_accuracy: 0.8585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa4982fc2e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "transformer.fit(\n",
    "    x=train_dataset,\n",
    "    epochs=4,\n",
    "    validation_data=vali_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd42c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_layers = 2\n",
    "# d_model = 128\n",
    "# dff = 512\n",
    "# num_heads = 8\n",
    "# dropout_rate = 0.1\n",
    "# input_node_dim = 24\n",
    "# target_node_dim = 24\n",
    "# Model: \"transformer_1\"\n",
    "# _________________________________________________________________\n",
    "#  Layer (type)                Output Shape              Param #   \n",
    "# =================================================================\n",
    "#  encoder_1 (Encoder)         multiple                  1322624   \n",
    "                                                                 \n",
    "#  decoder_1 (Decoder)         multiple                  2378112   \n",
    "                                                                 \n",
    "#  dense_29 (Dense)            multiple                  3096      \n",
    "                                                                 \n",
    "# =================================================================\n",
    "# Total params: 3,703,832\n",
    "# Trainable params: 3,703,832\n",
    "# Non-trainable params: 0\n",
    "# _________________________________________________________________\n",
    "# 1. 1000(16) 100轮 loss: 1100->255\n",
    "# 2. 1000(8) 100轮 loss: 281->233\n",
    "# 3. 1000(4) 100轮 loss: 277->206\n",
    "# 4. 2000(2) 100轮 loss: 272->244 在12-36个epoch降不下去，像是batch太少\n",
    "# 5. 1000(8) 100轮 loss: 265->191 再100轮 loss:190->146 再100轮 loss:147->119\n",
    "# 6. 1000(2) 10轮 loss: 304->239 又被打乱了\n",
    "# 7. 1000(16) 400轮 loss: 255->102 期间在100附近震荡很多次\n",
    "# 8. 100(4) 100轮 loss: 373->27\n",
    "# 9. 100(4) 100轮 loss: 485->36\n",
    "# 10. 100(4) 100轮 loss: 458->45\n",
    "# 11. 500(8) 100轮 loss: 438->117\n",
    "\n",
    "# 注意，transformer由于有填充，损失函数是不考虑这部分的。\n",
    "# 其次，序列通过均方来作为损失函数，进行回归是不是有问题，很难收敛，\n",
    "# 考虑到注意力机制是观察另一个向量，是不是应该用分类，而不是向量的回归，\n",
    "\n",
    "# 此外，我们要AI做到一是布局方式，二是节点裁剪，这里是不是不需要让AI映射每一个值？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6924a18",
   "metadata": {},
   "source": [
    "## 5.使用网络预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4fac76eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema:  [1, 0, 0, 41, 99, 29, 52, 86, 86, 52, 24, 37]\n",
      "flutter length:  11 value:  [2, 1, 0, 29, 52, 86, 86, 52, 24, 37, 998]\n",
      "predict length:  11 value:  [2, 1, 0, 29, 52, 52, 52, 52, 24, 37, 998]\n",
      "distance:  [0, 0, 0, 0, 0, 34, 34, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def d2c(schema, flutter, max_length=100):\n",
    "    '''\n",
    "    schema: 设计稿schema, 为一个一维向量\n",
    "    flutter: 实际Flutter节点输出，为一个一维向量，用于测试翻译的结果\n",
    "    \n",
    "    特殊数字：996填充，997开始，998结束，999节点分割符\n",
    "    '''\n",
    "    # 组织batch为1结构，作为网络输入输出\n",
    "    input1 = tf.constant([schema])\n",
    "    predict = [[997]]\n",
    "    for i in range(max_length):\n",
    "        p = transformer((input1, tf.constant(predict)), training=False)\n",
    "        p = p[:, -1:, :]\n",
    "        p_id = tf.argmax(p, axis=-1)[0].numpy().tolist()[0]\n",
    "        predict[0].append(p_id)\n",
    "        if (p_id == 998):\n",
    "            break\n",
    "    predict = predict[0][1:]\n",
    "    print(\"schema: \", schema)\n",
    "    print(\"flutter length: \", len(flutter), \"value: \", flutter)\n",
    "    print(\"predict length: \", len(predict), \"value: \", predict)\n",
    "    print(\"distance: \", [flutter[i] - predict[i] for i in range(min(len(flutter), len(predict)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5abb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机生成一个进行预测\n",
    "input1, input2, output = demo_generate_data(1)\n",
    "d2c(input1[0], output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d70c986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema:  [1, 56, 71, 250, 787, 26, 152, 118, 86, 120, 56, 78]\n",
      "flutter length:  19 value:  [1, 1, 0, 56, 71, 0, 0, 999, 2, 2, 1, 26, 152, 118, 86, 120, 56, 78, 998]\n",
      "predict length:  19 value:  [1, 1, 0, 56, 71, 0, 0, 999, 2, 2, 1, 26, 152, 118, 86, 120, 56, 78, 998]\n",
      "distance:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "schema = [1, 56, 71, 250, 787, 26, 152, 118, 86, 120, 56, 78]\n",
    "flutter = [1, 1, 0, 56, 71, 0, 0, 999, 2, 2, 1, 26, 152, 118, 86, 120, 56, 78, 998]\n",
    "d2c(schema, flutter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69038bac",
   "metadata": {},
   "source": [
    "## 6.保存模型的权重，方便下一次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ecefddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存训练权重\n",
    "transformer.save_weights(save_weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca566c",
   "metadata": {},
   "source": [
    "## 7.保存整个模型，方便迁移到其他地方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a2a9326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as positional_embedding_layer_call_fn, positional_embedding_layer_call_and_return_conditional_losses, dropout_1_layer_call_fn, dropout_1_layer_call_and_return_conditional_losses, positional_embedding_1_layer_call_fn while saving (showing 5 of 88). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/model_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/model_1/assets\n"
     ]
    }
   ],
   "source": [
    "# 直接加载模型\n",
    "# transformer = tf.saved_model.load(\"model2\")\n",
    "# 保存模型\n",
    "tf.saved_model.save(transformer, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
