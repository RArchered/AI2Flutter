{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62dd6393",
   "metadata": {},
   "source": [
    "## 1.导入依赖以及网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41ec386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载网络结构\n",
    "%run AI2Flutter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e843ce40",
   "metadata": {},
   "source": [
    "## 2.实例化网络，并设置模型输入形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a88463e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_1 (Encoder)         multiple                  1322624   \n",
      "                                                                 \n",
      " decoder_1 (Decoder)         multiple                  2378112   \n",
      "                                                                 \n",
      " dense_29 (Dense)            multiple                  3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,703,832\n",
      "Trainable params: 3,703,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "num_layers = 2\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "input_node_dim = 24  # demo中均使用24维向量\n",
    "target_node_dim = 24  # \n",
    "\n",
    "# 权重保存位置\n",
    "save_weight_path = \"./model_weight/model_1\"\n",
    "save_path = \"./model/model_1\"\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_node_dim=input_node_dim,\n",
    "    target_node_dim=target_node_dim,\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "# 优化器采用Adam，学习率自定义\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "transformer.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer=optimizer,\n",
    ")\n",
    "# 设置模型输入形状\n",
    "transformer((tf.keras.layers.Input(shape=(None, input_node_dim,)),\n",
    "             tf.keras.layers.Input(shape=(None, target_node_dim,))))\n",
    "# 网络概览\n",
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae69974",
   "metadata": {},
   "source": [
    "## 3.加载已经训练的权重，方便继续训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87e42df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x139ea2c40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载已训练权重\n",
    "transformer.load_weights(save_weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e276f7f",
   "metadata": {},
   "source": [
    "## 4.加载数据集训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d72bf980",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run AI2Flutter_demo_data.py\n",
    "# 数据规模\n",
    "train_seqs_num = 500\n",
    "validation_seqs_num = 30\n",
    "# 生成随机数据集\n",
    "input_data, output_data, output_label = demo_generate_data(train_seqs_num)\n",
    "vali_input_data, vali_output_data, vali_output_label = demo_generate_data(validation_seqs_num)\n",
    "\n",
    "# 训练集\n",
    "train_input = tf.data.Dataset.from_generator(\n",
    "    lambda: input_data, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, input_node_dim), dtype=tf.float32)))\n",
    "train_output = tf.data.Dataset.from_generator(\n",
    "    lambda: output_data, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, target_node_dim), dtype=tf.float32)))\n",
    "train_label = tf.data.Dataset.from_generator(\n",
    "    lambda: output_label, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, target_node_dim), dtype=tf.float32)))\n",
    "train_dataset = tf.data.Dataset.zip(((train_input, train_output), train_label))\n",
    "# batch设置\n",
    "train_dataset = train_dataset.padded_batch(8)\n",
    "\n",
    "# 验证集\n",
    "vali_input = tf.data.Dataset.from_generator(\n",
    "    lambda: vali_input_data, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, input_node_dim), dtype=tf.float32)))\n",
    "vali_output = tf.data.Dataset.from_generator(\n",
    "    lambda: vali_output_data, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, target_node_dim), dtype=tf.float32)))\n",
    "vali_label = tf.data.Dataset.from_generator(\n",
    "    lambda: vali_output_label, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, target_node_dim), dtype=tf.float32)))\n",
    "vali_dataset = tf.data.Dataset.zip(((vali_input, vali_output), vali_label))\n",
    "vali_dataset = vali_dataset.padded_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e83116a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 438.6826\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 364.0146\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 325.3456\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 292.0977\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 278.5095\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 273.9828\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 254.9693\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 251.2502\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 239.0785\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 248.9503\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 227.1818\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 233.8894\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 224.9428\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 224.5744\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 224.6346\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 213.9892\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 211.9939\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 209.4931\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 214.0139\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 225.0023\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 196.7424\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 213.0987\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 199.8421\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 201.7990\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 207.5272\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 197.3209\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 193.5958\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 193.2802\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 190.5901\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 196.8778\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 177.1940\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 174.0336\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 188.4457\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 177.0157\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 172.4126\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 172.3101\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 182.1293\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 165.9763\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 166.5088\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 164.5105\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 175.0611\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 161.1291\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 158.5467\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 161.0140\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 158.6568\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 164.8619\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 156.4813\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 166.0822\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 162.2845\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 143.9189\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 166.9944\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 158.2166\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 165.1462\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 148.8295\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 159.7674\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 161.5978\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 147.0293\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 163.7412\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 163.7060\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 132.4872\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 142.2173\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 164.6967\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 149.2694\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 144.0834\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 149.8008\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 147.6628\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 133.5812\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 150.3589\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 134.6002\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 144.8014\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 142.6290\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 155.7721\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 130.8754\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 129.0947\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 138.5556\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 127.9688\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 123.2827\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 126.5155\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 139.5854\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 132.7604\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 143.9065\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 127.8506\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 140.7182\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 140.2322\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 132.6938\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 123.0282\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 125.2326\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 135.1209\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 115.0498\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 110.3103\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 116.8982\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 128.9280\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 115.1529\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 121.1492\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 120.9493\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 122.4816\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 113.7548\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 14ms/step - loss: 129.3351\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 128.1791\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 117.3335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f67a4ba9220>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "transformer.fit(\n",
    "    x=train_dataset,\n",
    "    epochs=100,\n",
    "#     validation_data=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd42c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_layers = 2\n",
    "# d_model = 128\n",
    "# dff = 512\n",
    "# num_heads = 8\n",
    "# dropout_rate = 0.1\n",
    "# input_node_dim = 24\n",
    "# target_node_dim = 24\n",
    "# Model: \"transformer_1\"\n",
    "# _________________________________________________________________\n",
    "#  Layer (type)                Output Shape              Param #   \n",
    "# =================================================================\n",
    "#  encoder_1 (Encoder)         multiple                  1322624   \n",
    "                                                                 \n",
    "#  decoder_1 (Decoder)         multiple                  2378112   \n",
    "                                                                 \n",
    "#  dense_29 (Dense)            multiple                  3096      \n",
    "                                                                 \n",
    "# =================================================================\n",
    "# Total params: 3,703,832\n",
    "# Trainable params: 3,703,832\n",
    "# Non-trainable params: 0\n",
    "# _________________________________________________________________\n",
    "# 1. 1000(16) 100轮 loss: 1100->255\n",
    "# 2. 1000(8) 100轮 loss: 281->233\n",
    "# 3. 1000(4) 100轮 loss: 277->206\n",
    "# 4. 2000(2) 100轮 loss: 272->244 在12-36个epoch降不下去，像是batch太少\n",
    "# 5. 1000(8) 100轮 loss: 265->191 再100轮 loss:190->146 再100轮 loss:147->119\n",
    "# 6. 1000(2) 10轮 loss: 304->239 又被打乱了\n",
    "# 7. 1000(16) 400轮 loss: 255->102 期间在100附近震荡很多次\n",
    "# 8. 100(4) 100轮 loss: 373->27\n",
    "# 9. 100(4) 100轮 loss: 485->36\n",
    "# 10. 100(4) 100轮 loss: 458->45\n",
    "# 11. 500(8) 100轮 loss: 438->117\n",
    "\n",
    "# 注意，transformer由于有填充，损失函数是不考虑这部分的。其次，序列通过均方来作为损失函数，进行回归是不是有问题，是不是应该用分类？\n",
    "# 考虑到注意力机制是观察另一个向量，是不是应该用分类，而不是向量的回归，\n",
    "# 这个难度比值的回归难太多了，深圳我怀疑比nlp都困难，主要是根本收敛不了。。\n",
    "# 此外，我们要AI做到一是布局方式，二是节点裁剪，这里是不是不需要让AI映射每一个值？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6924a18",
   "metadata": {},
   "source": [
    "## 5.使用网络预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4fac76eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.  0. -1.  8. 33. -5. 28. -6.  1.  1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   -1. -1. -1. -1. -1. -1. -1.]]], shape=(1, 1, 24), dtype=float32)\n",
      "[2, 2, 1, 19, 255, 0, 255, 0, 24, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "***************\n",
      "[[[  -2.230118     -2.2769947    -1.7701182   -10.594133   -222.26733\n",
      "     -4.714891   -227.40027      -6.48445     -22.81416     -18.860962\n",
      "     -0.79332674   -0.7928952    -0.7933324    -0.7934217    -0.7935638\n",
      "     -0.79332376   -0.792983     -0.79374325   -0.7929125    -0.7930898\n",
      "     -0.7934303    -0.79340845   -0.7934934    -0.7929172 ]]]\n",
      "102188.484\n"
     ]
    }
   ],
   "source": [
    "# # 预测，基于原先的全是1的样本，网络似乎学会了把任何数字全部映射为1\n",
    "# input1 = tf.zeros((1,5,24))\n",
    "# input2 = tf.constant([[[\n",
    "#     12526,-52,-97877773352,45,5,6,7,8,9,10,-22099995,-12,13,999,15,167866687,17,18,19,10,0,0,0,0\n",
    "# ]]])\n",
    "# # input2 = tf.ones((1, 1, 24))\n",
    "# # input2 = tf.zeros((1, 1, 24))\n",
    "# input2 = tf.cast(input2, tf.float32)\n",
    "# re = transformer((input1, input2), training=False)\n",
    "# print(input2)\n",
    "# print(re)\n",
    "# print(tf.reduce_sum(tf.abs(re - tf.ones((1, 1, 24)))))\n",
    "\n",
    "input1, input2, output = demo_generate_data(1)\n",
    "start = [[[-1 for i in range(output_seq_dim)]]]\n",
    "p1 = transformer((tf.constant(input1), tf.constant(start)), training=False)\n",
    "print(tf.round(p1))\n",
    "print(output[0][0])\n",
    "print(\"***************\")\n",
    "d = np.array(p1 - output[0][0])\n",
    "print(d)\n",
    "print(np.sum(d**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69038bac",
   "metadata": {},
   "source": [
    "## 6.保存模型的权重，方便下一次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ecefddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存训练权重\n",
    "transformer.save_weights(save_weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca566c",
   "metadata": {},
   "source": [
    "## 7.保存整个模型，方便迁移到其他地方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a2a9326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as positional_embedding_layer_call_fn, positional_embedding_layer_call_and_return_conditional_losses, dropout_1_layer_call_fn, dropout_1_layer_call_and_return_conditional_losses, positional_embedding_1_layer_call_fn while saving (showing 5 of 88). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/model_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/model_1/assets\n"
     ]
    }
   ],
   "source": [
    "# 直接加载模型\n",
    "# transformer = tf.saved_model.load(\"model2\")\n",
    "# 保存模型\n",
    "tf.saved_model.save(transformer, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
