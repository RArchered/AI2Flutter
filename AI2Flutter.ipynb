{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60fa4d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 21:20:37.344707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e75e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 位置编码矩阵，输入length为序列长度，depth为单个token向量的长度\n",
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "  \n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49af89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 位置编码层\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    # 使用全链接层对输入向量（已经编码）映射到模型的维度\n",
    "    self.embedding = tf.keras.layers.Dense(d_model, activation='relu') \n",
    "    self.pos_encoding = positional_encoding(length=256, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "#     assert length <= 256, \"序列长度不能超过256\"\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e7f44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=float32, numpy=\n",
       "array([[ 0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         1.        ],\n",
       "       [ 0.84147096,  0.04639922,  0.00215443,  0.5403023 ,  0.998923  ,\n",
       "         0.9999977 ],\n",
       "       [ 0.9092974 ,  0.0926985 ,  0.00430886, -0.41614684,  0.9956942 ,\n",
       "         0.9999907 ],\n",
       "       [ 0.14112   ,  0.1387981 ,  0.00646326, -0.9899925 ,  0.9903207 ,\n",
       "         0.99997914]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_encoding(4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1569e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础注意力层，一个多头注意力层、一个正则化层，一个残差add操作\n",
    "# 输入一个头数和向量维数\n",
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8420b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉注意力层，输入x查询向量，会在上下文key、value中查询\n",
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "    # 残差连接\n",
    "    x = self.add([x, attn_output])\n",
    "    # 层norm化\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c9c37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
       "array([[[ 0.99381536, -0.99381536],\n",
       "        [ 0.99381536, -0.99381536],\n",
       "        [ 0.99381536, -0.99381536]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross = CrossAttention(num_heads=1, key_dim=4)\n",
    "cross(tf.ones((1,3,2)), tf.ones((1,4,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9397c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自注意力层\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b1e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 带因果掩码的自注意力层\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fbc93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前馈层\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x) \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c06e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码器\n",
    "# 输入模型维数（即输入单个向量的维数，因为transformer层不改变向量维数），多头头数，前馈中间层大小，drop率\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf5b450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2)\n",
      "(1, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(d_model=2, num_heads=8, dff=2048, dropout_rate=0.1)\n",
    "pt = tf.ones((1,3,2))\n",
    "print(pt.shape)\n",
    "print(sample_encoder_layer(pt).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a050c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码器\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df63d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解码器层\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d402a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2)\n",
      "(1, 20, 2)\n",
      "(1, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(d_model=2, num_heads=8, dff=2048)\n",
    "\n",
    "x = tf.ones((1,3,2))\n",
    "context = pt = tf.ones((1,20,2))\n",
    "sample_decoder_layer_output = sample_decoder_layer(\n",
    "    x=x, context=context)\n",
    "\n",
    "print(x.shape)\n",
    "print(context.shape)\n",
    "print(sample_decoder_layer_output.shape)  # `(batch_size, seq_len, d_model)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06da2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解码器\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f68e139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2)\n",
      "(1, 20, 2)\n",
      "(1, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=1, d_model=2, vocab_size=3, num_heads=8, dff=2048)\n",
    "\n",
    "x = tf.ones((1,3,2))\n",
    "context = pt = tf.ones((1,20,2))\n",
    "sample_decoder_output = sample_decoder(\n",
    "    x=x, context=context)\n",
    "\n",
    "print(x.shape)\n",
    "print(context.shape)\n",
    "print(sample_decoder_layer_output.shape)  # `(batch_size, seq_len, d_model)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50687504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer最终结构\n",
    "# output_size为最终输出的向量的维数，在文本翻译过程中是词向量的长度，但在这里是flutter组件节点向量\n",
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    print(x.shape)\n",
    "    print(context.shape)\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    try:\n",
    "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "      # b/250038731\n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d06e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59927fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def get_config(self):\n",
    "    config = {\n",
    "    'd_model': self.d_model,\n",
    "    'warmup_steps': self.warmup_steps,\n",
    "\n",
    "     }\n",
    "    return config\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab83119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "num_layers = 4\n",
    "d_model = 126\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=10,\n",
    "    target_vocab_size=20,\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "# 优化器\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "transformer.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b6291d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x13e632160>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_weights(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c4444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "313c7300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "(None, 3, 20)\n",
      "(None, 3, 126)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/mean_squared_error/BroadcastGradientArgs' defined at (most recent call last):\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/qv/lkzvp5v136j4x83fvc1qbgs00000gn/T/ipykernel_3223/2181739854.py\", line 1, in <module>\n      transformer.fit((tf.ones((1,3,10)), tf.ones((1,3,20))),tf.ones((1,3,21)),\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/engine/training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/mean_squared_error/BroadcastGradientArgs'\nIncompatible shapes: [1,3,20] vs. [1,3,21]\n\t [[{{node gradient_tape/mean_squared_error/BroadcastGradientArgs}}]] [Op:__inference_train_function_27504]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m21\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/mean_squared_error/BroadcastGradientArgs' defined at (most recent call last):\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/qv/lkzvp5v136j4x83fvc1qbgs00000gn/T/ipykernel_3223/2181739854.py\", line 1, in <module>\n      transformer.fit((tf.ones((1,3,10)), tf.ones((1,3,20))),tf.ones((1,3,21)),\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/engine/training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"/Users/archer/Documents/jupyter/venv_workspace/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/mean_squared_error/BroadcastGradientArgs'\nIncompatible shapes: [1,3,20] vs. [1,3,21]\n\t [[{{node gradient_tape/mean_squared_error/BroadcastGradientArgs}}]] [Op:__inference_train_function_27504]"
     ]
    }
   ],
   "source": [
    "transformer.fit((tf.ones((1,3,10)), tf.ones((1,3,20))),tf.ones((1,3,20)),\n",
    "                epochs=200,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54a8af38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 20)\n",
      "(1, 3, 126)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 20), dtype=float32, numpy=\n",
       "array([[[-0.05242896, -0.02938414,  0.05024254,  0.04878366,\n",
       "          0.02481437, -0.03367698, -0.01460284,  0.11665189,\n",
       "         -0.05826628, -0.01462948, -0.0827505 ,  0.00564265,\n",
       "          0.0510062 , -0.0692454 ,  0.03574026,  0.01222372,\n",
       "          0.05528903, -0.02998143,  0.05311131, -0.00769812]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer([tf.ones((1,3,10)), tf.ones((1,1,20))], training=False) - tf.ones((1,1,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "769c6473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  2566778   \n",
      "                                                                 \n",
      " decoder_1 (Decoder)         multiple                  4613774   \n",
      "                                                                 \n",
      " dense_25 (Dense)            multiple                  2540      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,183,092\n",
      "Trainable params: 7,183,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c197b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 在nlp中，最后一层通过dense层，将模型维数扩展为词汇数，通过softmax取得最大概率的坐标，这个坐标和实际值zuo cha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_workspace_kernel",
   "language": "python",
   "name": "venv_workspace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
